{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a decision tree with the training set\n",
    "\n",
    "Drug <A>\n",
    "Drug <B>\n",
    "- age\n",
    "  - young\n",
    "    - sex\n",
    "      - F <A>\n",
    "      - M <B>\n",
    "  - middle-age <B>\n",
    "  - senior\n",
    "    - cholesterol\n",
    "      - high <A>\n",
    "      - normal <B>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each \"internal node\" corresponds to a test.\n",
    "- And each \"branch\" corresponds to a result of the test.\n",
    "- And each \"leaf node\" assigns a patient to a class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Choose an attribute from dataset\n",
    "2- Calculate the significance of the attribute in the splitting of the data.\n",
    "3- Split the data based on the value of the best attribute.\n",
    "4- Go to step1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are built using  recursive partitioning  classify teh data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- More predictiveness\n",
    "- Less Impurity\n",
    "- Lower Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Pure Node\":A node in the tree is considered pure if.in all of the cases,the nodes fail into a spesific category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrpoy\n",
    "Information disorder or randomness in the data\n",
    "The etropy is used to calculate the homogeneity of the samples in that node.\n",
    "-  # TODO Entropy formula "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The tree with the higher information gain after splitting.\"\n",
    "Information gain= Entropy before split -Weighted entropy after split"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
